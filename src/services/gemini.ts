
import { GoogleGenAI, GenerateContentResponse, Type } from "@google/genai";
import { Attachment, AttachmentType, HealthRiskLevel } from "../types";
import { MODEL_NAME, SYSTEM_INSTRUCTION } from "../constants";
import { sanitizeForAI, safeJsonParse } from "../utils/security";

// Helper to safely access environment variables
const getEnv = (key: string): string | undefined => {
  if (typeof process !== 'undefined' && process.env && process.env[key]) {
    return process.env[key] as string;
  }
  return undefined;
};

// Helper to clean base64 string for API usage (removes data URI prefix)
const cleanBase64 = (data: string) => {
  return data.replace(/^data:(.*,)?/, '');
};

// Helper to map raw errors to user-friendly messages
const mapGeminiError = (error: any): string => {
  const msg = error.message || '';
  if (msg.includes('400')) return "The request was invalid. This may be due to a corrupt image or unsupported file format.";
  if (msg.includes('403') || msg.includes('API key')) return "Authentication failed. Please check the system API Key configuration.";
  if (msg.includes('429') || msg.includes('Quota')) return "System is currently overloaded (Quota Exceeded). Please try again in a minute.";
  if (msg.includes('500') || msg.includes('503')) return "AI Service is temporarily unavailable. Please try again later.";
  if (msg.includes('SAFETY') || msg.includes('blocked')) return "The AI model blocked the response due to safety filters. Please rephrase your query.";
  return "Unable to generate analysis at this time.";
};

export const generateHealthAnalysis = async (
  prompt: string,
  attachments: Attachment[],
  previousHistory: string
): Promise<string> => {
  try {
    const apiKey = getEnv('API_KEY');
    if (!apiKey) {
      throw new Error("System Configuration Error: API Key not found.");
    }

    const ai = new GoogleGenAI({ apiKey });
    
    // Prepare parts array
    const parts: any[] = [];

    // Add attachments
    attachments.forEach(att => {
      parts.push({
        inlineData: {
          mimeType: att.mimeType,
          data: cleanBase64(att.data)
        }
      });
    });

    // SECURITY: Sanitize input to prevent Prompt Injection (XML Tag Breakout)
    const safePrompt = sanitizeForAI(prompt);
    const safeHistory = sanitizeForAI(previousHistory);

    // SECURITY: Wrap prompt in XML tags to separate data from instructions
    const fullPrompt = `
<system_context>
Analyze the following health data based on your system instructions.
${safeHistory ? `PREVIOUS HISTORY CONTEXT:\n${safeHistory}` : ''}
</system_context>

<user_input>
${safePrompt}
</user_input>
`;
    
    parts.push({ text: fullPrompt });

    const response: GenerateContentResponse = await ai.models.generateContent({
      model: MODEL_NAME,
      contents: {
        role: 'user',
        parts: parts
      },
      config: {
        systemInstruction: SYSTEM_INSTRUCTION,
        temperature: 0.4, // Lower temperature for more consistent medical-style output
      }
    });

    if (!response.text) {
      // Check if it was blocked
      if (response.candidates && response.candidates[0]?.finishReason) {
         throw new Error(`AI Generation Blocked: ${response.candidates[0].finishReason}`);
      }
      throw new Error("No response generated by the model.");
    }

    return response.text;

  } catch (error: any) {
    console.error("Gemini API Error:", error);
    // Throw a clean error message for the UI to display
    throw new Error(mapGeminiError(error));
  }
};

// Helper for structured classification
export const classifyHealthRequest = async (
  prompt: string, 
  attachments: Attachment[]
): Promise<{ analysis_type: string; preliminary_concern: HealthRiskLevel }> => {
  try {
    const apiKey = getEnv('API_KEY');
    if (!apiKey) return { analysis_type: 'Unknown', preliminary_concern: 'Medium' };

    const ai = new GoogleGenAI({ apiKey });

    // We use gemini-2.5-flash for fast, structured classification
    const modelName = 'gemini-2.5-flash';

    const parts: any[] = [];
    attachments.forEach(att => {
      parts.push({
        inlineData: {
          mimeType: att.mimeType,
          data: cleanBase64(att.data)
        }
      });
    });

    // SECURITY: Sanitize prompt for classification as well
    const safePrompt = sanitizeForAI(prompt);

    parts.push({ text: `
      Analyze the input and classify it.
      
      User Input: "${safePrompt}"
      
      Tasks:
      1. Determine the 'analysis_type'. Options: 'Text Only', 'Image Analysis', 'Audio Analysis', 'Document Review', 'Mixed Multimodal'.
      2. Determine the 'preliminary_concern' based on symptoms described or visible. Options: 'Low', 'Medium', 'High'.
         - Low: Minor symptoms, cold, cosmetic issues.
         - Medium: Persistent pain, fever, concerning visual signs, or ambiguous/unsure situations.
         - High: Severe pain, breathing issues, severe bleeding, chest pain, confusion.
      
      Return JSON. MANDATORY: preliminary_concern MUST be Low, Medium, or High.
    `});

    const response = await ai.models.generateContent({
      model: modelName,
      contents: { role: 'user', parts },
      config: {
        responseMimeType: 'application/json',
        responseSchema: {
          type: Type.OBJECT,
          properties: {
            analysis_type: { type: Type.STRING },
            preliminary_concern: { type: Type.STRING, enum: ['Low', 'Medium', 'High'] }
          },
          required: ["analysis_type", "preliminary_concern"]
        }
      }
    });

    if (response.text) {
      // SECURITY: Use safe parsing with integrity check
      const validator = (obj: any) => {
        return obj && typeof obj.analysis_type === 'string' && ['Low', 'Medium', 'High'].includes(obj.preliminary_concern);
      };

      const json = safeJsonParse<{ analysis_type: string; preliminary_concern: HealthRiskLevel }>(
        response.text, 
        validator
      );

      if (json) {
        return {
          analysis_type: json.analysis_type,
          preliminary_concern: json.preliminary_concern
        };
      }
    }
    
    return { analysis_type: 'Unknown', preliminary_concern: 'Medium' };
  } catch (e) {
    console.warn("Classification failed", e);
    // Fallback defaults, do not throw here as classification is secondary
    return { analysis_type: 'Unknown', preliminary_concern: 'Medium' };
  }
};
